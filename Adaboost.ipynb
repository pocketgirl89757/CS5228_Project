{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 5228\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Imports\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import locale\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import *\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "locale.setlocale(locale.LC_ALL,'')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Training Data\n",
    "# drop_columns = ['CreateJob','RetainedJob','City','Name','Zip','BankState']\n",
    "\n",
    "# drop_columns = ['CreateJob','ApprovalFY','ApprovalDate','DisbursementGross','SBA_Appv']\n",
    "\n",
    "\n",
    "# drop_columns = []\n",
    "\n",
    "le = generate_labels()\n",
    "\n",
    "base_dropna = get_data(le=le,type='train', dropna=True, get_dummy=True, feature_split=False, values_only=True,drop_columns=drop_columns)\n",
    "base_fillna = get_data(le=le,type='train', dropna=False, get_dummy=True, feature_split=False, values_only=True,drop_columns=drop_columns)\n",
    "feature_dropna = get_data(le=le,type='train', dropna=True, get_dummy=True, feature_split=True, values_only=True,drop_columns=drop_columns)\n",
    "feature_fillna = get_data(le=le,type='train', dropna=False, get_dummy=True, feature_split=True, values_only=True,drop_columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49808 entries, 0 to 49999\n",
      "Data columns (total 28 columns):\n",
      "Name                 49808 non-null int64\n",
      "City                 49808 non-null int64\n",
      "State                49808 non-null int64\n",
      "Zip                  49808 non-null int32\n",
      "Bank                 49808 non-null int64\n",
      "BankState            49808 non-null int64\n",
      "NAICS                49808 non-null int32\n",
      "ApprovalDate         49808 non-null int64\n",
      "ApprovalFY           49808 non-null int16\n",
      "Term                 49808 non-null int64\n",
      "NoEmp                49808 non-null int64\n",
      "CreateJob            49808 non-null int64\n",
      "RetainedJob          49808 non-null int64\n",
      "FranchiseCode        49808 non-null int32\n",
      "DisbursementDate     49808 non-null int64\n",
      "DisbursementGross    49808 non-null float32\n",
      "GrAppv               49808 non-null float32\n",
      "SBA_Appv             49808 non-null float32\n",
      "ChargeOff            49808 non-null int64\n",
      "NewExist_1           49808 non-null uint8\n",
      "NewExist_2           49808 non-null uint8\n",
      "UrbanRural_0         49808 non-null uint8\n",
      "UrbanRural_1         49808 non-null uint8\n",
      "UrbanRural_2         49808 non-null uint8\n",
      "RevLineCr_N          49808 non-null uint8\n",
      "RevLineCr_Y          49808 non-null uint8\n",
      "LowDoc_N             49808 non-null uint8\n",
      "LowDoc_Y             49808 non-null uint8\n",
      "dtypes: float32(3), int16(1), int32(3), int64(12), uint8(9)\n",
      "memory usage: 6.6 MB\n"
     ]
    }
   ],
   "source": [
    "base_dropna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Test Data\n",
    "# feature_test = get_data(le=le,type='test', dropna=False, get_dummy=True, feature_split=True, values_only=True,drop_columns=drop_columns)\n",
    "base_test = get_data(le=le,type='test', dropna=False, get_dummy=True, feature_split=False, values_only=True,drop_columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dropna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['KNN', 'LR', 'DT', 'RF', 'GBM']\n",
    "base_dropna_f1 = []\n",
    "base_dropna_acc = []\n",
    "base_fillna_f1 = []\n",
    "base_fillna_acc = []\n",
    "feature_dropna_f1 = []\n",
    "feature_dropna_acc = []\n",
    "feature_fillna_f1 = []\n",
    "feature_fillna_acc = []\n",
    "\n",
    "def calculate_acc_and_f1(classifier, x_train, y_train, x_test, y_test):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    f1 = round(f1_score(y_test, y_pred, average='weighted') * 100, 2)\n",
    "    acc = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "    return f1, acc\n",
    "\n",
    "    \n",
    "def train_single_classifier(classifier, df_in, f1_list, acc_list):\n",
    "    df_x = df_in.drop(columns='ChargeOff')\n",
    "    df_y = df_in['ChargeOff']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.25, random_state=0)\n",
    "    f1, acc = calculate_acc_and_f1(classifier, x_train, y_train, x_test, y_test)\n",
    "    f1_list.append(f1)\n",
    "    acc_list.append(acc)\n",
    "    \n",
    "\n",
    "def train_model(df_in, f1_list, acc_list):\n",
    "    train_single_classifier(KNeighborsClassifier(), df_in, f1_list, acc_list)\n",
    "    train_single_classifier(LogisticRegression(), df_in, f1_list, acc_list)\n",
    "    train_single_classifier(DecisionTreeClassifier(), df_in, f1_list, acc_list)\n",
    "    train_single_classifier(RandomForestClassifier(), df_in, f1_list, acc_list)\n",
    "    train_single_classifier(GradientBoostingClassifier(), df_in, f1_list, acc_list)\n",
    "    \n",
    "\n",
    "train_model(base_dropna, base_dropna_f1, base_dropna_acc)\n",
    "train_model(base_fillna, base_fillna_f1, base_fillna_acc)\n",
    "train_model(feature_dropna, feature_dropna_f1, feature_dropna_acc)\n",
    "train_model(feature_fillna, feature_fillna_f1, feature_fillna_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_record = pd.DataFrame({'Model': model_names, 'base_dropna_acc': base_dropna_acc, 'base_fillna_acc': base_fillna_acc, 'feature_dropna_acc': feature_dropna_acc, 'feature_fillna_acc': feature_fillna_acc})\n",
    "# accuracy_record = pd.DataFrame({'Model': model_names, 'base_dropna_acc': base_dropna_acc, 'feature_dropna_acc': feature_dropna_acc})\n",
    "accuracy_record['acc_mean'] = accuracy_record.mean(axis=1).round(2)\n",
    "accuracy_record.set_index('Model', inplace=True)\n",
    "accuracy_record.loc['avg'] = accuracy_record.mean()\n",
    "\n",
    "F1_record = pd.DataFrame({'Model': model_names, 'base_dropna_f1': base_dropna_f1, 'base_fillna_f1': base_fillna_f1, 'feature_dropna_f1': feature_dropna_f1, 'feature_fillna_f1': feature_fillna_f1})\n",
    "# F1_record = pd.DataFrame({'Model': model_names, 'base_dropna_f1': base_dropna_f1, 'feature_dropna_f1': feature_dropna_f1})\n",
    "F1_record['F1_mean'] = F1_record.mean(axis=1).round(2)\n",
    "F1_record.set_index('Model', inplace=True)\n",
    "F1_record.loc['avg'] = F1_record.mean()\n",
    "\n",
    "print(accuracy_record)\n",
    "print('\\n')\n",
    "print(F1_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "base_dropna_x = base_dropna.drop(columns='ChargeOff')\n",
    "base_dropna_y = base_dropna['ChargeOff']\n",
    "model.fit(base_dropna_x, base_dropna_y)\n",
    "test_pred = model.predict(base_test)\n",
    "pd.DataFrame(test_pred).to_csv('y_pred.csv',header=['ChargeOff'],index_label=\"Id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_grid: \n",
      " {'loss': ['deviance', 'exponential'], 'learning_rate': [0.05, 0.1, 0.3], 'n_estimators': [50, 100, 150], 'subsample': [0.9, 1], 'criterion': ['friedman_mse', 'mse', 'mae']}\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   12.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9aa1a305f3fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mlr_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mlr_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#Predict values based on new parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(base_dropna_x, base_dropna_y, test_size = 0.25, random_state=0)\n",
    "\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "# c = np.append(np.logspace(0, 4, 20),[0.001,.009,0.01,.09,1,5,10,25,100])\n",
    "# param_grid = {'loss': ['deviance', 'exponential'],\n",
    "#               'learning_rate': [0.001,0.05,0.1,0.2,0.5],\n",
    "#               'n_estimators':[50,100,200,500,1000],\n",
    "#               'subsample':[0.9,1],\n",
    "#               'criterion':['friedman_mse', 'mse', 'mae'],\n",
    "#               'min_samples_split':[2,5,10]\n",
    "#              }\n",
    "\n",
    "param_grid = {'loss': ['deviance', 'exponential'],\n",
    "              'learning_rate': [0.05,0.1,0.3],\n",
    "              'n_estimators':[50,100,150],\n",
    "              'subsample':[0.9,1],\n",
    "              'criterion':['friedman_mse', 'mse', 'mae'],\n",
    "#               'min_samples_split':[2,5],\n",
    "#               'max_depth':[3,5,7],\n",
    "#               'max_features':['sqrt','log2', None],\n",
    "              \n",
    "             }\n",
    "print('param_grid: \\n',param_grid)\n",
    "\n",
    "lr_cv = GridSearchCV(clf, param_grid,scoring = 'accuracy',verbose=10,n_jobs=-1)\n",
    "lr_cv.fit(x_train, y_train)\n",
    "\n",
    "#Predict values based on new parameters\n",
    "# y_pred_acc = lr_cv.predict(x_test)\n",
    "\n",
    "print(\"Best Parameters\",lr_cv.best_params_)\n",
    "print(\"Best Accuracy :\",lr_cv.best_score_)\n",
    "\n",
    "y_pred= lr_cv.predict(x_test)\n",
    "print(\"Accuracy: \",round(accuracy_score(y_test, y_pred) * 100, 2))\n",
    "print('Weighted F1 Mesure: ',round(f1_score(y_test, y_pred, average='weighted') * 100, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lr_cv.predict(base_test)\n",
    "pd.DataFrame(test_pred).to_csv('y_pred_grid_search.csv',header=['ChargeOff'],index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645099</td>\n",
       "      <td>0.714894</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.330273</td>\n",
       "      <td>0.858709</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.360423</td>\n",
       "      <td>0.321782</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.911940</td>\n",
       "      <td>0.399976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498425</td>\n",
       "      <td>0.778173</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.840948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.254401</td>\n",
       "      <td>0.081683</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906513</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.288509</td>\n",
       "      <td>0.489379</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.900229</td>\n",
       "      <td>0.077249</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.874273</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741188</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.766940</td>\n",
       "      <td>0.485436</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.535555</td>\n",
       "      <td>0.064291</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396040</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561105</td>\n",
       "      <td>0.027361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028081</td>\n",
       "      <td>0.470936</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.655367</td>\n",
       "      <td>0.232993</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.669321</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820954</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.200377</td>\n",
       "      <td>0.667260</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.811478</td>\n",
       "      <td>0.431597</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869252</td>\n",
       "      <td>0.099964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.637809</td>\n",
       "      <td>0.466675</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.891169</td>\n",
       "      <td>0.974084</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.874143</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744908</td>\n",
       "      <td>0.054962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.780104</td>\n",
       "      <td>0.256042</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.210432</td>\n",
       "      <td>0.527037</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.456773</td>\n",
       "      <td>0.262376</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906513</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.587171</td>\n",
       "      <td>0.161346</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.945189</td>\n",
       "      <td>0.077249</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.669321</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681790</td>\n",
       "      <td>0.139826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.422661</td>\n",
       "      <td>0.028937</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.453045</td>\n",
       "      <td>0.154996</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.521615</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.839615</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.995063</td>\n",
       "      <td>0.158993</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.809258</td>\n",
       "      <td>0.929978</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.256809</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876692</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.531241</td>\n",
       "      <td>0.493004</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.759018</td>\n",
       "      <td>0.161724</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.778146</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835834</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.551130</td>\n",
       "      <td>0.697469</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.330643</td>\n",
       "      <td>0.077249</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.551771</td>\n",
       "      <td>0.123762</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793206</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.094766</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.223102</td>\n",
       "      <td>0.955146</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.479786</td>\n",
       "      <td>0.240099</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.098371</td>\n",
       "      <td>0.713319</td>\n",
       "      <td>0.047962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.604763</td>\n",
       "      <td>0.658420</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.662127</td>\n",
       "      <td>0.600548</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.489064</td>\n",
       "      <td>0.032178</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.934260</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.914969</td>\n",
       "      <td>0.514119</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.295539</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.672661</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.032503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605684</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.265819</td>\n",
       "      <td>0.011447</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.500095</td>\n",
       "      <td>0.929978</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272123</td>\n",
       "      <td>0.329186</td>\n",
       "      <td>0.017961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.506568</td>\n",
       "      <td>0.533134</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.992773</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.478591</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781132</td>\n",
       "      <td>0.091764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.010650</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.770258</td>\n",
       "      <td>0.974084</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.482836</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454629</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.956807</td>\n",
       "      <td>0.775375</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.951130</td>\n",
       "      <td>0.230252</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.357197</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711428</td>\n",
       "      <td>0.069963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1     2         3         4         5         6   \\\n",
       "0   0.645099  0.714894  0.18  0.330273  0.858709  0.156863  0.360423   \n",
       "1   0.498425  0.778173  0.88  0.840948  1.000000  0.882353  0.254401   \n",
       "2   0.288509  0.489379  0.08  0.900229  0.077249  0.529412  0.874273   \n",
       "3   0.766940  0.485436  0.96  0.535555  0.064291  0.960784  0.000000   \n",
       "4   0.028081  0.470936  0.48  0.655367  0.232993  0.470588  0.669321   \n",
       "5   0.200377  0.667260  0.10  0.811478  0.431597  0.098039  0.479798   \n",
       "6   0.637809  0.466675  0.66  0.891169  0.974084  0.823529  0.874143   \n",
       "7   0.780104  0.256042  0.40  0.210432  0.527037  0.392157  0.456773   \n",
       "8   0.587171  0.161346  0.08  0.945189  0.077249  0.666667  0.669321   \n",
       "9   0.422661  0.028937  0.70  0.453045  0.154996  0.078431  0.521615   \n",
       "10  0.995063  0.158993  0.10  0.809258  0.929978  0.686275  0.256809   \n",
       "11  0.531241  0.493004  0.86  0.759018  0.161724  0.901961  0.778146   \n",
       "12  0.551130  0.697469  0.18  0.330643  0.077249  0.529412  0.551771   \n",
       "13  0.094766  0.007504  0.90  0.223102  0.955146  0.607843  0.479786   \n",
       "14  0.604763  0.658420  0.32  0.662127  0.600548  0.470588  0.489064   \n",
       "15  0.914969  0.514119  0.38  0.021480  0.295539  0.372549  0.672661   \n",
       "16  0.265819  0.011447  0.24  0.500095  0.929978  0.235294  0.000000   \n",
       "17  0.506568  0.533134  0.96  0.535585  0.992773  0.960784  0.478591   \n",
       "18  0.010650  0.391949  0.86  0.770258  0.974084  0.862745  0.482836   \n",
       "19  0.956807  0.775375  0.08  0.951130  0.230252  0.862745  0.357197   \n",
       "\n",
       "          7         8         9         10        11        12   13   14   15  \\\n",
       "0   0.321782  0.002500  0.000000  0.000000  0.911940  0.399976  1.0  0.0  0.0   \n",
       "1   0.081683  0.000600  0.000341  0.000000  0.906513  0.003360  1.0  0.0  0.0   \n",
       "2   0.148515  0.000100  0.000114  0.000000  0.741188  0.003360  1.0  0.0  0.0   \n",
       "3   0.396040  0.000100  0.000000  0.000000  0.561105  0.027361  0.0  1.0  1.0   \n",
       "4   0.250000  0.000200  0.000227  0.000000  0.820954  0.004960  1.0  0.0  0.0   \n",
       "5   0.673267  0.000300  0.000227  0.000000  0.869252  0.099964  1.0  0.0  0.0   \n",
       "6   0.742574  0.000500  0.000568  0.000000  0.744908  0.054962  1.0  0.0  0.0   \n",
       "7   0.262376  0.000100  0.000114  0.000000  0.906513  0.014961  0.0  1.0  0.0   \n",
       "8   0.742574  0.000500  0.000568  0.000000  0.681790  0.139826  1.0  0.0  0.0   \n",
       "9   0.024752  0.001500  0.001705  0.000000  0.839615  0.019961  1.0  0.0  0.0   \n",
       "10  0.207921  0.000100  0.000114  0.000000  0.876692  0.004960  1.0  0.0  0.0   \n",
       "11  0.207921  0.001100  0.001250  0.000000  0.835834  0.004960  0.0  1.0  0.0   \n",
       "12  0.123762  0.000100  0.000000  0.000000  0.793206  0.004960  0.0  1.0  0.0   \n",
       "13  0.240099  0.001800  0.002045  0.098371  0.713319  0.047962  1.0  0.0  0.0   \n",
       "14  0.032178  0.000300  0.000341  0.000000  0.934260  0.004960  0.0  1.0  0.0   \n",
       "15  0.297030  0.032503  0.000000  0.000000  0.605684  0.019961  1.0  0.0  1.0   \n",
       "16  0.207921  0.002500  0.000000  0.272123  0.329186  0.017961  1.0  0.0  1.0   \n",
       "17  0.594059  0.001400  0.001591  0.000000  0.781132  0.091764  1.0  0.0  0.0   \n",
       "18  0.158416  0.000100  0.000000  0.000000  0.454629  0.008960  0.0  1.0  1.0   \n",
       "19  0.061881  0.002000  0.002273  0.000000  0.711428  0.069963  1.0  0.0  0.0   \n",
       "\n",
       "     16   17   18   19   20   21  \n",
       "0   1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "1   1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "2   1.0  0.0  0.0  1.0  1.0  0.0  \n",
       "3   0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "4   1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "5   0.0  1.0  1.0  0.0  1.0  0.0  \n",
       "6   1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "7   0.0  1.0  1.0  0.0  1.0  0.0  \n",
       "8   1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "9   0.0  1.0  1.0  0.0  1.0  0.0  \n",
       "10  1.0  0.0  0.0  1.0  1.0  0.0  \n",
       "11  1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "12  1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "13  1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "14  1.0  0.0  0.0  1.0  1.0  0.0  \n",
       "15  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "16  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "17  0.0  1.0  1.0  0.0  1.0  0.0  \n",
       "18  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "19  1.0  0.0  1.0  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize + K-fold\n",
    "base_dropna_x = base_dropna.drop(columns='ChargeOff')\n",
    "base_dropna_y = base_dropna['ChargeOff']\n",
    "\n",
    "min_max_scaler_x = preprocessing.MinMaxScaler()\n",
    "\n",
    "min_max_scaler_x.fit(base_dropna_x)\n",
    "\n",
    "\n",
    "base_dropna_x_scaled = min_max_scaler_x.transform(base_dropna_x)\n",
    "base_dropna_x_normalized = pd.DataFrame(base_dropna_x_scaled)\n",
    "\n",
    "\n",
    "\n",
    "base_dropna_x_normalized.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.9231450475662941\n",
      "Best Parameters {'learning_rate': 0.5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(base_dropna_x_normalized, base_dropna_y, test_size = 0.25, random_state=0)\n",
    "\n",
    "# Train Model\n",
    "clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3))\n",
    "param_grid = {'learning_rate': [0.5],\n",
    "#               'loss': ['exponential'],\n",
    "#               'max_depth':[8],\n",
    "#               'max_features':[None],\n",
    "              'n_estimators':[50,100,200,300],\n",
    "#               'min_samples_split':[2],\n",
    "              \n",
    "             }\n",
    "\n",
    "# param_grid ={}\n",
    "model = GridSearchCV(clf, param_grid,scoring = 'accuracy', cv=10,n_jobs=-1)\n",
    "model.fit(base_dropna_x_normalized, base_dropna_y)\n",
    "\n",
    "# # Validation\n",
    "# test_pred = model.predict(x_test)\n",
    "# f1 = round(f1_score(y_test, test_pred, average='weighted') * 100, 2)\n",
    "# acc = round(accuracy_score(y_test, test_pred) * 100, 2)\n",
    "# print(\"f1=\", f1, \"acc=\", acc)\n",
    "\n",
    "print(\"Best Accuracy :\",model.best_score_)\n",
    "print(\"Best Parameters\",model.best_params_)\n",
    "\n",
    "\n",
    "# Prediction\n",
    "x_scaled = min_max_scaler_x.transform(base_test)\n",
    "test_normalized = pd.DataFrame(x_scaled)\n",
    "\n",
    "test_pred = model.predict(test_normalized)\n",
    "pd.DataFrame(test_pred).to_csv('y_pred.csv',header=['ChargeOff'],index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters {'learning_rate': 0.5, 'loss': 'exponential', 'max_depth': 8, 'max_features': None, 'min_samples_split': 4, 'n_estimators': 310}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149808, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

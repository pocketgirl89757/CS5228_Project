{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 5228\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Imports\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import locale\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "locale.setlocale(locale.LC_ALL,'')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Training Data\n",
    "drop_columns = ['CreateJob','RetainedJob','City','Name','Zip','BankState']\n",
    "\n",
    "# drop_columns = []\n",
    "\n",
    "le = generate_labels()\n",
    "\n",
    "base_dropna = get_data(le=le,type='train', dropna=True, get_dummy=True, feature_split=False, values_only=True,drop_columns=drop_columns)\n",
    "base_fillna = get_data(le=le,type='train', dropna=False, get_dummy=True, feature_split=False, values_only=True,drop_columns=drop_columns)\n",
    "feature_dropna = get_data(le=le,type='train', dropna=True, get_dummy=True, feature_split=True, values_only=True,drop_columns=drop_columns)\n",
    "feature_fillna = get_data(le=le,type='train', dropna=False, get_dummy=True, feature_split=True, values_only=True,drop_columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49808 entries, 0 to 49999\n",
      "Data columns (total 28 columns):\n",
      "Name                 49808 non-null int64\n",
      "City                 49808 non-null int64\n",
      "State                49808 non-null int64\n",
      "Zip                  49808 non-null int32\n",
      "Bank                 49808 non-null int64\n",
      "BankState            49808 non-null int64\n",
      "NAICS                49808 non-null int32\n",
      "ApprovalDate         49808 non-null int64\n",
      "ApprovalFY           49808 non-null int16\n",
      "Term                 49808 non-null int64\n",
      "NoEmp                49808 non-null int64\n",
      "CreateJob            49808 non-null int64\n",
      "RetainedJob          49808 non-null int64\n",
      "FranchiseCode        49808 non-null int32\n",
      "DisbursementDate     49808 non-null int64\n",
      "DisbursementGross    49808 non-null float32\n",
      "GrAppv               49808 non-null float32\n",
      "SBA_Appv             49808 non-null float32\n",
      "ChargeOff            49808 non-null int64\n",
      "NewExist_1           49808 non-null uint8\n",
      "NewExist_2           49808 non-null uint8\n",
      "UrbanRural_0         49808 non-null uint8\n",
      "UrbanRural_1         49808 non-null uint8\n",
      "UrbanRural_2         49808 non-null uint8\n",
      "RevLineCr_N          49808 non-null uint8\n",
      "RevLineCr_Y          49808 non-null uint8\n",
      "LowDoc_N             49808 non-null uint8\n",
      "LowDoc_Y             49808 non-null uint8\n",
      "dtypes: float32(3), int16(1), int32(3), int64(12), uint8(9)\n",
      "memory usage: 6.6 MB\n"
     ]
    }
   ],
   "source": [
    "base_dropna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Test Data\n",
    "# feature_test = get_data(le=le,type='test', dropna=False, get_dummy=True, feature_split=True, values_only=True,drop_columns=drop_columns)\n",
    "base_test = get_data(le=le,type='test', dropna=False, get_dummy=True, feature_split=False, values_only=True,drop_columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dropna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['KNN', 'LR', 'DT', 'RF', 'GBM']\n",
    "base_dropna_f1 = []\n",
    "base_dropna_acc = []\n",
    "base_fillna_f1 = []\n",
    "base_fillna_acc = []\n",
    "feature_dropna_f1 = []\n",
    "feature_dropna_acc = []\n",
    "feature_fillna_f1 = []\n",
    "feature_fillna_acc = []\n",
    "\n",
    "def calculate_acc_and_f1(classifier, x_train, y_train, x_test, y_test):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    f1 = round(f1_score(y_test, y_pred, average='weighted') * 100, 2)\n",
    "    acc = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "    return f1, acc\n",
    "\n",
    "    \n",
    "def train_single_classifier(classifier, df_in, f1_list, acc_list):\n",
    "    df_x = df_in.drop(columns='ChargeOff')\n",
    "    df_y = df_in['ChargeOff']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.25, random_state=0)\n",
    "    f1, acc = calculate_acc_and_f1(classifier, x_train, y_train, x_test, y_test)\n",
    "    f1_list.append(f1)\n",
    "    acc_list.append(acc)\n",
    "    \n",
    "\n",
    "def train_model(df_in, f1_list, acc_list):\n",
    "    train_single_classifier(KNeighborsClassifier(), df_in, f1_list, acc_list)\n",
    "    train_single_classifier(LogisticRegression(), df_in, f1_list, acc_list)\n",
    "    train_single_classifier(DecisionTreeClassifier(), df_in, f1_list, acc_list)\n",
    "    train_single_classifier(RandomForestClassifier(), df_in, f1_list, acc_list)\n",
    "    train_single_classifier(GradientBoostingClassifier(), df_in, f1_list, acc_list)\n",
    "    \n",
    "\n",
    "train_model(base_dropna, base_dropna_f1, base_dropna_acc)\n",
    "train_model(base_fillna, base_fillna_f1, base_fillna_acc)\n",
    "train_model(feature_dropna, feature_dropna_f1, feature_dropna_acc)\n",
    "train_model(feature_fillna, feature_fillna_f1, feature_fillna_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_record = pd.DataFrame({'Model': model_names, 'base_dropna_acc': base_dropna_acc, 'base_fillna_acc': base_fillna_acc, 'feature_dropna_acc': feature_dropna_acc, 'feature_fillna_acc': feature_fillna_acc})\n",
    "# accuracy_record = pd.DataFrame({'Model': model_names, 'base_dropna_acc': base_dropna_acc, 'feature_dropna_acc': feature_dropna_acc})\n",
    "accuracy_record['acc_mean'] = accuracy_record.mean(axis=1).round(2)\n",
    "accuracy_record.set_index('Model', inplace=True)\n",
    "accuracy_record.loc['avg'] = accuracy_record.mean()\n",
    "\n",
    "F1_record = pd.DataFrame({'Model': model_names, 'base_dropna_f1': base_dropna_f1, 'base_fillna_f1': base_fillna_f1, 'feature_dropna_f1': feature_dropna_f1, 'feature_fillna_f1': feature_fillna_f1})\n",
    "# F1_record = pd.DataFrame({'Model': model_names, 'base_dropna_f1': base_dropna_f1, 'feature_dropna_f1': feature_dropna_f1})\n",
    "F1_record['F1_mean'] = F1_record.mean(axis=1).round(2)\n",
    "F1_record.set_index('Model', inplace=True)\n",
    "F1_record.loc['avg'] = F1_record.mean()\n",
    "\n",
    "print(accuracy_record)\n",
    "print('\\n')\n",
    "print(F1_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "base_dropna_x = base_dropna.drop(columns='ChargeOff')\n",
    "base_dropna_y = base_dropna['ChargeOff']\n",
    "model.fit(base_dropna_x, base_dropna_y)\n",
    "test_pred = model.predict(base_test)\n",
    "pd.DataFrame(test_pred).to_csv('y_pred.csv',header=['ChargeOff'],index_label=\"Id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(base_dropna_x, base_dropna_y, test_size = 0.25, random_state=0)\n",
    "\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "# c = np.append(np.logspace(0, 4, 20),[0.001,.009,0.01,.09,1,5,10,25,100])\n",
    "# param_grid = {'loss': ['deviance', 'exponential'],\n",
    "#               'learning_rate': [0.001,0.05,0.1,0.2,0.5],\n",
    "#               'n_estimators':[50,100,200,500,1000],\n",
    "#               'subsample':[0.9,1],\n",
    "#               'criterion':['friedman_mse', 'mse', 'mae'],\n",
    "#               'min_samples_split':[2,5,10]\n",
    "#              }\n",
    "\n",
    "param_grid = {'loss': ['deviance', 'exponential'],\n",
    "              'learning_rate': [0.05,0.1,0.3],\n",
    "              'n_estimators':[50,100,150],\n",
    "              'subsample':[0.9,1],\n",
    "              'criterion':['friedman_mse', 'mse', 'mae'],\n",
    "#               'min_samples_split':[2,5],\n",
    "#               'max_depth':[3,5,7],\n",
    "#               'max_features':['sqrt','log2', None],\n",
    "              \n",
    "             }\n",
    "print('param_grid: \\n',param_grid)\n",
    "\n",
    "lr_cv = GridSearchCV(clf, param_grid,scoring = 'accuracy',verbose=10,n_jobs=-1)\n",
    "lr_cv.fit(x_train, y_train)\n",
    "\n",
    "#Predict values based on new parameters\n",
    "# y_pred_acc = lr_cv.predict(x_test)\n",
    "\n",
    "print(\"Best Parameters\",lr_cv.best_params_)\n",
    "print(\"Best Accuracy :\",lr_cv.best_score_)\n",
    "\n",
    "y_pred= lr_cv.predict(x_test)\n",
    "print(\"Accuracy: \",round(accuracy_score(y_test, y_pred) * 100, 2))\n",
    "print('Weighted F1 Mesure: ',round(f1_score(y_test, y_pred, average='weighted') * 100, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lr_cv.predict(base_test)\n",
    "pd.DataFrame(test_pred).to_csv('y_pred_grid_search.csv',header=['ChargeOff'],index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.9319387349268853\n"
     ]
    }
   ],
   "source": [
    "# Normalize + K-fold\n",
    "base_dropna_x = base_dropna.drop(columns='ChargeOff')\n",
    "base_dropna_y = base_dropna['ChargeOff']\n",
    "\n",
    "min_max_scaler_x = preprocessing.MinMaxScaler()\n",
    "full_x = pd.concat([base_dropna_x, base_test], axis=0)\n",
    "\n",
    "min_max_scaler_x.fit(full_x)\n",
    "\n",
    "\n",
    "base_dropna_x_scaled = min_max_scaler_x.transform(base_dropna_x)\n",
    "base_dropna_x_normalized = pd.DataFrame(base_dropna_x_scaled)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(base_dropna_x_normalized, base_dropna_y, test_size = 0.25, random_state=0)\n",
    "\n",
    "# Train Model\n",
    "clf = GradientBoostingClassifier()\n",
    "param_grid = {'learning_rate': [0.5],\n",
    "              'loss': ['exponential'],\n",
    "              'max_depth':[8],\n",
    "              'max_features':[None],\n",
    "              'n_estimators':[310],\n",
    "              'min_samples_split':[2],\n",
    "              \n",
    "             }\n",
    "model = GridSearchCV(clf, param_grid,scoring = 'accuracy', cv=5,n_jobs=-1)\n",
    "model.fit(base_dropna_x_normalized, base_dropna_y)\n",
    "\n",
    "# # Validation\n",
    "# test_pred = model.predict(x_test)\n",
    "# f1 = round(f1_score(y_test, test_pred, average='weighted') * 100, 2)\n",
    "# acc = round(accuracy_score(y_test, test_pred) * 100, 2)\n",
    "# print(\"f1=\", f1, \"acc=\", acc)\n",
    "\n",
    "print(\"Best Accuracy :\",model.best_score_)\n",
    "\n",
    "\n",
    "# Prediction\n",
    "x_scaled = min_max_scaler_x.transform(base_test)\n",
    "test_normalized = pd.DataFrame(x_scaled)\n",
    "\n",
    "test_pred = model.predict(test_normalized)\n",
    "pd.DataFrame(test_pred).to_csv('y_pred.csv',header=['ChargeOff'],index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149808, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
